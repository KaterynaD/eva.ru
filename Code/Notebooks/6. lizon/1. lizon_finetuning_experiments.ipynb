{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning experiments to create a best model to find clones between eva.ru forum users based on user lizon. Different transformers models, number of epochs and different training approaches avaiable in ktrain library are tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1944,
     "status": "ok",
     "timestamp": 1636088909977,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "5BGlJw7Qqz1w",
    "outputId": "56ffe103-b933-4187-b8b8-9b3864c6fe29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1636088911907,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "w6F76Ds1rKS1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1636088912241,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "Vhr_6dF-rAcO",
    "outputId": "187ba559-0b0b-4247-e681-ca3f34f82a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "######## GPU CONFIGS FOR RTX 2070 ###############\n",
    "## Please ignore if not training on GPU       ##\n",
    "## this is important for running CuDNN on GPU ##\n",
    "\n",
    "tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
    "\n",
    "# chck if GPU can be seen by TF\n",
    "tf.config.list_physical_devices('GPU')\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1636088912243,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "yMGG5rtkWT8L",
    "outputId": "5366b89c-c736-47e4-84be-5cfa31c43e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 54.8 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1636088912244,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "EppjlNx6WENy",
    "outputId": "482d1fb2-23a1-4a82-fac7-412a583d7724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  5 05:08:32 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    40W / 300W |    425MiB / 16160MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1636088912245,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "L-5_9QCkrPfw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1636088912246,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "bvnxCGjM2nKr"
   },
   "outputs": [],
   "source": [
    "#experiment duration\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1636088912246,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "RvfS4EaGvpK5"
   },
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1636088912635,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "wF0xp1UfvmZ0"
   },
   "outputs": [],
   "source": [
    "#Saving into log (Excel file)\n",
    "import openpyxl \n",
    "def SaveToExperimentLog(Experiments_file, LogEntry, data):\n",
    "    book = openpyxl.load_workbook(Experiments_file)\n",
    "    writer = pd.ExcelWriter(Experiments_file, engine='openpyxl') \n",
    "    writer.book = book\n",
    "\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "    data.to_excel(writer, LogEntry[0:29],index=False)\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1636088912635,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "K3tGK-juvfDl"
   },
   "outputs": [],
   "source": [
    "#!pip install pycm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1636088912636,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "Is-PfhFpvMVj"
   },
   "outputs": [],
   "source": [
    "#to get score metrics from the model and save in the experiment log\n",
    "import pycm as cm\n",
    "def model_metrics(np_confusion_matrix,class_names):\n",
    "  #converting numpy array to dictionary\n",
    "  d_confusion_matrix={}\n",
    "  for i in range(len(class_names)):\n",
    "    d_confusion_matrix[class_names[i]]=dict(zip(class_names, np_confusion_matrix[i]))\n",
    "  d_confusion_matrix=eval(str(d_confusion_matrix))  \n",
    "  model_cm=cm.ConfusionMatrix(matrix=d_confusion_matrix)\n",
    "  return model_cm.weighted_average('F1'), model_cm.Kappa, model_cm.PPV, model_cm.TPR, model_cm.F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1636088912636,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "FLUBzlkbrSnQ"
   },
   "outputs": [],
   "source": [
    "########## Ensure reproducibility ##########\n",
    "\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(42)\n",
    "\n",
    "#Does not work with ktrain\n",
    "#os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "#random.seed(42)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(42)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1636088912637,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "3xqprIhGrVfG"
   },
   "outputs": [],
   "source": [
    "#!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1329,
     "status": "ok",
     "timestamp": 1636088913958,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "nmSlFi7HrqA-"
   },
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1636088913961,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "Su60OiMLrtjq"
   },
   "outputs": [],
   "source": [
    "Data = '/content/drive/MyDrive/Colab Notebooks/Projects/eva/Data/'\n",
    "\n",
    "Messages_filename='lizon_data_for_finetuning.csv'\n",
    "Messages_full_filename=os.path.join(Data, Messages_filename)\n",
    "\n",
    "train_Messages_filename='lizon_data_for_finetuning_train_t.csv'\n",
    "train_Messages_full_filename=os.path.join(Data, train_Messages_filename)\n",
    "\n",
    "valid_Messages_filename='lizon_data_for_finetuning_valid_t.csv'\n",
    "valid_Messages_full_filename=os.path.join(Data, valid_Messages_filename)\n",
    "\n",
    "test_Messages_filename='lizon_clon_data_for_testg.csv'\n",
    "test_Messages_full_filename=os.path.join(Data, test_Messages_filename)\n",
    "\n",
    "text_column='message'\n",
    "target_column='target'\n",
    "\n",
    "Models = '/content/drive/MyDrive/Colab Notebooks/Projects/eva/Models/'\n",
    "\n",
    "#Experiment\n",
    "#Experiments log file \n",
    "Experiments_file='/content/drive/MyDrive/Colab Notebooks/Projects/eva/ExperimentLogs/lizon.xlsx'\n",
    "Experiment_name='applied_final'\n",
    "#Experiment can be continued from the lines in the configuration tab (Experiment_name) without results (NewExecution=False) or started from scratch ignoring previous results (NewExecution=True)\n",
    "NewExecution=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87qH-eX0xOeI"
   },
   "source": [
    "## Experiment\n",
    "Experiment is configured in an experiment log file (Excel file, in my case,  in different tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBqkgZbixUDJ"
   },
   "source": [
    "1. Reading an experiment configuration (Experiment_name) from an experiment log file (Experiments_file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1636088914819,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "bGm3GyzsxIPH",
    "outputId": "04aa26aa-ea5b-4fa0-c2c5-503048fc4838"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "      <th>method</th>\n",
       "      <th>weighted_avg_F1</th>\n",
       "      <th>kappa</th>\n",
       "      <th>lizon-precision</th>\n",
       "      <th>lizon-recall</th>\n",
       "      <th>lizon-f1-score</th>\n",
       "      <th>duration</th>\n",
       "      <th>comment</th>\n",
       "      <th>test_weighted_avg_F1</th>\n",
       "      <th>test_kappa</th>\n",
       "      <th>test_lizon-precision</th>\n",
       "      <th>test_lizon-recall</th>\n",
       "      <th>test_lizon-f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepPavlov/rubert-base-cased-conversational</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>fit_onecycle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blinoff/roberta-base-russian-v0</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>fit_onecycle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model  ...  test_lizon-f1-score\n",
       "0  DeepPavlov/rubert-base-cased-conversational  ...                  NaN\n",
       "1              blinoff/roberta-base-russian-v0  ...                  NaN\n",
       "\n",
       "[2 rows x 18 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment = pd.read_excel(open(Experiments_file, 'rb'), sheet_name=Experiment_name)\n",
    "Experiment['comment'].apply(str)\n",
    "Experiment.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FD6FDGDcybXh"
   },
   "source": [
    "## Data load and/or split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1662,
     "status": "ok",
     "timestamp": 1636088916476,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "PjAF2rw9qgOe",
    "outputId": "09de1378-3b5f-4898-8816-f1fa221388e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test files exist\n"
     ]
    }
   ],
   "source": [
    "## split dataset\n",
    "from sklearn import  model_selection\n",
    "from pathlib import Path\n",
    "\n",
    "test_file = Path(test_Messages_full_filename)\n",
    "train_file = Path(train_Messages_full_filename)\n",
    "valid_file = Path(valid_Messages_full_filename)\n",
    "\n",
    "if (test_file.is_file() and train_file.is_file() and valid_file.is_file()):\n",
    "  print('Train/Valid/Test files exist')\n",
    "  df_test=pd.read_csv(test_Messages_full_filename, error_bad_lines=False, index_col=False, usecols=[target_column, text_column])\n",
    "  df_train=pd.read_csv(train_Messages_full_filename, error_bad_lines=False, index_col=False, usecols=[target_column, text_column])\n",
    "  df_valid=pd.read_csv(valid_Messages_full_filename, error_bad_lines=False, index_col=False, usecols=[target_column, text_column])\n",
    "else:\n",
    "  print('Train/Valid/Test files do  NOT  exist. Splitting...')\n",
    "  df=pd.read_csv(Messages_full_filename, error_bad_lines=False, index_col=False, usecols=[target_column, text_column])\n",
    "  #df.groupby(['target']).size().reset_index(name='counts').sort_values('counts', ascending=False)\n",
    "  df_trainvalid, df_test = model_selection.train_test_split(df, test_size=0.3, random_state=42,shuffle=True)\n",
    "  df_test.to_csv(test_Messages_full_filename, header=True, index=False)\n",
    "\n",
    "  df_train, df_valid = model_selection.train_test_split(df_trainvalid, test_size=0.3, random_state=42,shuffle=True)\n",
    "  df_train.to_csv(train_Messages_full_filename, header=True, index=False)\n",
    "  df_valid.to_csv(valid_Messages_full_filename, header=True, index=False)\n",
    "\n",
    "#\n",
    "x_test = df_test[text_column].values.astype(str)\n",
    "x_train = df_train[text_column].values.astype(str)\n",
    "x_valid = df_valid[text_column].values.astype(str)\n",
    "\n",
    "## get target\n",
    "y_test = df_test[target_column].values.astype(str)\n",
    "y_train = df_train[target_column].values.astype(str)\n",
    "y_valid = df_valid[target_column].values.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erFSIPkJ2-3F"
   },
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gDX6nTazVkJ"
   },
   "source": [
    "## Custom Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1636088916478,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "6Ua6M0pLlOb4"
   },
   "outputs": [],
   "source": [
    "#https://lars76.github.io/2018/09/27/loss-functions-for-segmentation.html\n",
    "\n",
    "def focal_loss(alpha=0.25, gamma=2):\n",
    "  def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
    "    targets = tf.cast(targets, tf.float32)\n",
    "    weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
    "    weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
    "    \n",
    "    return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b \n",
    "\n",
    "  def loss(y_true, logits):\n",
    "    y_pred = tf.math.sigmoid(logits)\n",
    "    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "  return loss\n",
    "#-------------------------------------------------------------------------------  \n",
    "def dice_loss(smooth=1e-7):\n",
    "  def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.math.sigmoid(y_pred)\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred + smooth)\n",
    "\n",
    "    return 1 - numerator / denominator\n",
    "  return dice_coef\n",
    "#-------------------------------------------------------------------------------\n",
    "def tversky_loss(beta=0.5):\n",
    "  def loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.math.sigmoid(y_pred)\n",
    "    numerator = y_true * y_pred\n",
    "    denominator = y_true * y_pred + beta * (1 - y_true) * y_pred + (1 - beta) * y_true * (1 - y_pred)\n",
    "\n",
    "    return 1 - tf.reduce_sum(numerator) / tf.reduce_sum(denominator)\n",
    "\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1636088916480,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "NowPo4agHBAj"
   },
   "outputs": [],
   "source": [
    "def combined_loss_focal(alpha=0.25, gamma=2):\n",
    "  def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
    "    targets = tf.cast(targets, tf.float32)\n",
    "    weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
    "    weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
    "    \n",
    "    return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b \n",
    "\n",
    "  def loss(y_true, logits):\n",
    "    y_pred = tf.math.sigmoid(logits)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(tf.cast(y_true, tf.float32), y_pred) + focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "  return loss\n",
    "\n",
    "def combined_loss_focalm(alpha=0.25, gamma=2):\n",
    "  def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
    "    targets = tf.cast(targets, tf.float32)\n",
    "    weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
    "    weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
    "    \n",
    "    return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b \n",
    "\n",
    "  def loss(y_true, logits):\n",
    "    y_pred = tf.math.sigmoid(logits)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(tf.cast(y_true, tf.float32), y_pred) * focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1636088916481,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "R6m0NYKhtJlM"
   },
   "outputs": [],
   "source": [
    "def fit_onecycle(MODEL_NAME, maxlen=512,batch_size=8,lr=1e-5,epochs=1,ind=0, func=None):\n",
    "  t = text.Transformer(MODEL_NAME, maxlen=maxlen)\n",
    "  trn = t.preprocess_train(x_train, y_train)\n",
    "  val = t.preprocess_test(x_valid, y_valid)\n",
    "  test = t.preprocess_test(x_test, y_test)\n",
    "  model = t.get_classifier()\n",
    "  if func=='focal_loss':\n",
    "    model.compile(loss=focal_loss(alpha=0.25, gamma=2),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']) \n",
    "  elif func=='dice_loss':\n",
    "    model.compile(loss=dice_loss(smooth=1e-7),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])  \n",
    "  elif func=='tversky_loss':\n",
    "    model.compile(loss=tversky_loss(beta=0.5),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])     \n",
    "  elif func=='combined_loss_focal':\n",
    "    model.compile(loss=combined_loss_focal(alpha=0.25, gamma=2),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])        \n",
    "  elif func=='combined_loss_focalm':\n",
    "    model.compile(loss=combined_loss_focalm(alpha=0.25, gamma=2),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])     \n",
    "  learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=batch_size)\n",
    "  learner.fit_onecycle(lr=lr, epochs=epochs)\n",
    "  #predictor = ktrain.get_predictor(learner.model, preproc=t)\n",
    "  #Model_full_filename=os.path.join(Models, 'fit_onecycle_'+str(ind))\n",
    "  #predictor.save(Model_full_filename)\n",
    "  val_confusion_matrix=learner.validate(val_data=val, class_names=t.get_classes())\n",
    "  val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1 = model_metrics(np_confusion_matrix=val_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  test_confusion_matrix=learner.validate(val_data=test, class_names=t.get_classes())\n",
    "  test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = model_metrics(np_confusion_matrix=test_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  return val_weighted_avg_F1, val_kappa, val_PPV['lizon'], val_TPR['lizon'], val_F1['lizon'],test_weighted_avg_F1, test_kappa, test_PPV['lizon'], test_TPR['lizon'], test_F1['lizon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1636088916482,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "jpQ-K54zYolM"
   },
   "outputs": [],
   "source": [
    "def tria(MODEL_NAME, maxlen=512,batch_size=8,lr=1e-5,ind=0):\n",
    "  t = text.Transformer(MODEL_NAME, maxlen=maxlen)\n",
    "  trn = t.preprocess_train(x_train, y_train)\n",
    "  val = t.preprocess_test(x_valid, y_valid)\n",
    "  test = t.preprocess_test(x_test, y_test)\n",
    "  model = t.get_classifier()\n",
    "  learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=batch_size)\n",
    "  learner.autofit(lr=lr)\n",
    "  predictor = ktrain.get_predictor(learner.model, preproc=t)\n",
    "  #Model_full_filename=os.path.join(Models, 'fit_onecycle_'+str(ind))\n",
    "  #predictor.save(Model_full_filename)\n",
    "  val_confusion_matrix=learner.validate(val_data=val, class_names=t.get_classes())\n",
    "  val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1 = model_metrics(np_confusion_matrix=val_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  test_confusion_matrix=learner.validate(val_data=test, class_names=t.get_classes())\n",
    "  test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = model_metrics(np_confusion_matrix=test_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  return val_weighted_avg_F1, val_kappa, val_PPV['lizon'], val_TPR['lizon'], val_F1['lizon'],test_weighted_avg_F1, test_kappa, test_PPV['lizon'], test_TPR['lizon'], test_F1['lizon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1636088916483,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "QZBBYXIOalCy"
   },
   "outputs": [],
   "source": [
    "def SGDR1(MODEL_NAME, maxlen=512,batch_size=8,lr=1e-5,n_cycles=5, cycle_len=1, ind=0):\n",
    "  t = text.Transformer(MODEL_NAME, maxlen=maxlen)\n",
    "  trn = t.preprocess_train(x_train, y_train)\n",
    "  val = t.preprocess_test(x_valid, y_valid)\n",
    "  test = t.preprocess_test(x_test, y_test)\n",
    "  model = t.get_classifier()\n",
    "  learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=batch_size)\n",
    "  learner.fit(lr=lr, n_cycles=n_cycles, cycle_len=cycle_len)\n",
    "  predictor = ktrain.get_predictor(learner.model, preproc=t)\n",
    "  #Model_full_filename=os.path.join(Models, 'fit_onecycle_'+str(ind))\n",
    "  #predictor.save(Model_full_filename)\n",
    "  val_confusion_matrix=learner.validate(val_data=val, class_names=t.get_classes())\n",
    "  val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1 = model_metrics(np_confusion_matrix=val_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  test_confusion_matrix=learner.validate(val_data=test, class_names=t.get_classes())\n",
    "  test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = model_metrics(np_confusion_matrix=test_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  return val_weighted_avg_F1, val_kappa, val_PPV['lizon'], val_TPR['lizon'], val_F1['lizon'],test_weighted_avg_F1, test_kappa, test_PPV['lizon'], test_TPR['lizon'], test_F1['lizon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1636088916483,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "uKl3egZnpXvN"
   },
   "outputs": [],
   "source": [
    "def triareduced(MODEL_NAME, maxlen=512,batch_size=8,lr=1e-5,epochs=20, reduce_on_plateau=1, ind=0):\n",
    "  t = text.Transformer(MODEL_NAME, maxlen=maxlen)\n",
    "  trn = t.preprocess_train(x_train, y_train)\n",
    "  val = t.preprocess_test(x_valid, y_valid)\n",
    "  test = t.preprocess_test(x_test, y_test)\n",
    "  model = t.get_classifier()\n",
    "  learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=batch_size)\n",
    "  learner.autofit(  lr=lr, epochs=epochs, reduce_on_plateau=reduce_on_plateau)\n",
    "  predictor = ktrain.get_predictor(learner.model, preproc=t)\n",
    "  #Model_full_filename=os.path.join(Models, 'fit_onecycle_'+str(ind))\n",
    "  #predictor.save(Model_full_filename)\n",
    "  val_confusion_matrix=learner.validate(val_data=val, class_names=t.get_classes())\n",
    "  val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1 = model_metrics(np_confusion_matrix=val_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  test_confusion_matrix=learner.validate(val_data=test, class_names=t.get_classes())\n",
    "  test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = model_metrics(np_confusion_matrix=test_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  return val_weighted_avg_F1, val_kappa, val_PPV['lizon'], val_TPR['lizon'], val_F1['lizon'],test_weighted_avg_F1, test_kappa, test_PPV['lizon'], test_TPR['lizon'], test_F1['lizon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1636088916485,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "c7e5Q3BdWIOC"
   },
   "outputs": [],
   "source": [
    "def SGDR2(MODEL_NAME, maxlen=512,batch_size=8,lr=1e-5,n_cycles=5, cycle_len=1, cycle_mult=2, ind=0):\n",
    "  t = text.Transformer(MODEL_NAME, maxlen=maxlen)\n",
    "  trn = t.preprocess_train(x_train, y_train)\n",
    "  val = t.preprocess_test(x_valid, y_valid)\n",
    "  test = t.preprocess_test(x_test, y_test)\n",
    "  model = t.get_classifier()\n",
    "  learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=batch_size)\n",
    "  learner.fit(lr=lr, n_cycles=n_cycles, cycle_len=cycle_len, cycle_mult=cycle_mult)\n",
    "  predictor = ktrain.get_predictor(learner.model, preproc=t)\n",
    "  #Model_full_filename=os.path.join(Models, 'fit_onecycle_'+str(ind))\n",
    "  #predictor.save(Model_full_filename)\n",
    "  val_confusion_matrix=learner.validate(val_data=val, class_names=t.get_classes())\n",
    "  val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1 = model_metrics(np_confusion_matrix=val_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  test_confusion_matrix=learner.validate(val_data=test, class_names=t.get_classes())\n",
    "  test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = model_metrics(np_confusion_matrix=test_confusion_matrix,class_names=t.get_classes())\n",
    "\n",
    "  return val_weighted_avg_F1, val_kappa, val_PPV['lizon'], val_TPR['lizon'], val_F1['lizon'],test_weighted_avg_F1, test_kappa, test_PPV['lizon'], test_TPR['lizon'], test_F1['lizon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1955434,
     "status": "ok",
     "timestamp": 1636090871899,
     "user": {
      "displayName": "Kateryna Drogaieva",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjB1LQYJH97Lqm6RsCcAADFgzEAa0YxMUT7P4mjlA=s64",
      "userId": "10877377912113147805"
     },
     "user_tz": 420
    },
    "id": "cUtnGDEf11YZ",
    "outputId": "3437fa43-13e4-4ca4-852d-2bc9580e32d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DeepPavlov/rubert-base-cased-conversational started...\n",
      "Model                   DeepPavlov/rubert-base-cased-conversational\n",
      "maxlen                                                          512\n",
      "batch_size                                                        8\n",
      "epochs                                                            3\n",
      "lr                                                            2e-05\n",
      "method                                                 fit_onecycle\n",
      "weighted_avg_F1                                                 NaN\n",
      "kappa                                                           NaN\n",
      "lizon-precision                                                 NaN\n",
      "lizon-recall                                                    NaN\n",
      "lizon-f1-score                                                  NaN\n",
      "duration                                                        NaN\n",
      "comment                                                         NaN\n",
      "test_weighted_avg_F1                                            NaN\n",
      "test_kappa                                                      NaN\n",
      "test_lizon-precision                                            NaN\n",
      "test_lizon-recall                                               NaN\n",
      "test_lizon-f1-score                                             NaN\n",
      "Name: 0, dtype: object\n",
      "---------------------------------------------\n",
      "preprocessing train...\n",
      "language: ru\n",
      "train sequence lengths:\n",
      "\tmean : 57\n",
      "\t95percentile : 131\n",
      "\t99percentile : 222\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: ru\n",
      "test sequence lengths:\n",
      "\tmean : 56\n",
      "\t95percentile : 124\n",
      "\t99percentile : 210\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: ru\n",
      "test sequence lengths:\n",
      "\tmean : 58\n",
      "\t95percentile : 133\n",
      "\t99percentile : 222\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404 Client Error: Not Found for url: https://huggingface.co/DeepPavlov/rubert-base-cased-conversational/resolve/main/tf_model.h5\n",
      "/usr/local/lib/python3.7/dist-packages/ktrain/text/preprocessor.py:1067: UserWarning: Could not find Tensorflow version of model.  Attempting to download/load PyTorch version as TensorFlow model using from_pt=True. You will need PyTorch installed for this.\n",
      "  warnings.warn('Could not find Tensorflow version of model.  Attempting to download/load PyTorch version as TensorFlow model using from_pt=True. ' +\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/3\n",
      "592/592 [==============================] - 239s 375ms/step - loss: 0.2332 - accuracy: 0.9290 - val_loss: 0.1916 - val_accuracy: 0.9138\n",
      "Epoch 2/3\n",
      "592/592 [==============================] - 221s 371ms/step - loss: 0.1084 - accuracy: 0.9626 - val_loss: 0.1431 - val_accuracy: 0.9547\n",
      "Epoch 3/3\n",
      "592/592 [==============================] - 221s 371ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.1659 - val_accuracy: 0.9601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.96      0.99      0.98      1879\n",
      "       lizon       0.86      0.55      0.67       151\n",
      "\n",
      "    accuracy                           0.96      2030\n",
      "   macro avg       0.91      0.77      0.83      2030\n",
      "weighted avg       0.96      0.96      0.96      2030\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.96      0.99      0.97     11230\n",
      "       lizon       0.56      0.25      0.34       635\n",
      "\n",
      "    accuracy                           0.95     11865\n",
      "   macro avg       0.76      0.62      0.66     11865\n",
      "weighted avg       0.94      0.95      0.94     11865\n",
      "\n",
      "Processing blinoff/roberta-base-russian-v0 started...\n",
      "Model                   blinoff/roberta-base-russian-v0\n",
      "maxlen                                              256\n",
      "batch_size                                           16\n",
      "epochs                                                5\n",
      "lr                                                1e-05\n",
      "method                                     fit_onecycle\n",
      "weighted_avg_F1                                     NaN\n",
      "kappa                                               NaN\n",
      "lizon-precision                                     NaN\n",
      "lizon-recall                                        NaN\n",
      "lizon-f1-score                                      NaN\n",
      "duration                                            NaN\n",
      "comment                                             NaN\n",
      "test_weighted_avg_F1                                NaN\n",
      "test_kappa                                          NaN\n",
      "test_lizon-precision                                NaN\n",
      "test_lizon-recall                                   NaN\n",
      "test_lizon-f1-score                                 NaN\n",
      "Name: 1, dtype: object\n",
      "---------------------------------------------\n",
      "preprocessing train...\n",
      "language: ru\n",
      "train sequence lengths:\n",
      "\tmean : 57\n",
      "\t95percentile : 131\n",
      "\t99percentile : 222\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: ru\n",
      "test sequence lengths:\n",
      "\tmean : 56\n",
      "\t95percentile : 124\n",
      "\t99percentile : 210\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: ru\n",
      "test sequence lengths:\n",
      "\tmean : 58\n",
      "\t95percentile : 133\n",
      "\t99percentile : 222\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404 Client Error: Not Found for url: https://huggingface.co/blinoff/roberta-base-russian-v0/resolve/main/tf_model.h5\n",
      "/usr/local/lib/python3.7/dist-packages/ktrain/text/preprocessor.py:1067: UserWarning: Could not find Tensorflow version of model.  Attempting to download/load PyTorch version as TensorFlow model using from_pt=True. You will need PyTorch installed for this.\n",
      "  warnings.warn('Could not find Tensorflow version of model.  Attempting to download/load PyTorch version as TensorFlow model using from_pt=True. ' +\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 1e-05...\n",
      "Epoch 1/5\n",
      "296/296 [==============================] - 115s 337ms/step - loss: 0.2416 - accuracy: 0.9400 - val_loss: 0.2574 - val_accuracy: 0.9256\n",
      "Epoch 2/5\n",
      "296/296 [==============================] - 98s 329ms/step - loss: 0.1958 - accuracy: 0.9413 - val_loss: 0.2131 - val_accuracy: 0.9266\n",
      "Epoch 3/5\n",
      "296/296 [==============================] - 98s 329ms/step - loss: 0.1052 - accuracy: 0.9626 - val_loss: 0.1522 - val_accuracy: 0.9453\n",
      "Epoch 4/5\n",
      "296/296 [==============================] - 98s 330ms/step - loss: 0.0438 - accuracy: 0.9865 - val_loss: 0.1595 - val_accuracy: 0.9502\n",
      "Epoch 5/5\n",
      "296/296 [==============================] - 98s 329ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.1318 - val_accuracy: 0.9621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.97      0.99      0.98      1879\n",
      "       lizon       0.84      0.60      0.70       151\n",
      "\n",
      "    accuracy                           0.96      2030\n",
      "   macro avg       0.91      0.80      0.84      2030\n",
      "weighted avg       0.96      0.96      0.96      2030\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.98      0.98      0.98     11230\n",
      "       lizon       0.62      0.66      0.64       635\n",
      "\n",
      "    accuracy                           0.96     11865\n",
      "   macro avg       0.80      0.82      0.81     11865\n",
      "weighted avg       0.96      0.96      0.96     11865\n",
      "\n"
     ]
    }
   ],
   "source": [
    " for index, row in Experiment.iterrows():\n",
    "  print('Processing %s started...'%(row['Model']))\n",
    "  if (not(NewExecution) and row['duration'])>0:\n",
    "    print('%s is already processed. Continue'%(row['Model']))\n",
    "    continue  \n",
    "  \n",
    "  print(row)\n",
    "  print('---------------------------------------------')\n",
    "  try:\n",
    "    ts_start = time.time()\n",
    "    if row['method']=='fit_onecycle':\n",
    "      if 'func' in Experiment.columns:\n",
    "        val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1, test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = fit_onecycle(row['Model'],row['maxlen'],row['batch_size'],row['lr'],row['epochs'],index,row['func'])\n",
    "      else:\n",
    "        val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1, test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = fit_onecycle(row['Model'],row['maxlen'],row['batch_size'],row['lr'],row['epochs'],index)\n",
    "    elif row['method']=='tria':\n",
    "      val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1, test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = tria(row['Model'],row['maxlen'],row['batch_size'],row['lr'],index)   \n",
    "    elif row['method']=='SGDR1':\n",
    "      val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1, test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = SGDR1(row['Model'],row['maxlen'],row['batch_size'],row['lr'],row['n_cycles'],row['cycle_len'],index) \n",
    "    elif row['method']=='triareduced':\n",
    "      val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1, test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = triareduced(row['Model'],row['maxlen'],row['batch_size'],row['lr'],row['epochs'],row['reduce_on_plateau'],index)    \n",
    "    elif row['method']=='SGRD2':\n",
    "      val_weighted_avg_F1, val_kappa, val_PPV, val_TPR, val_F1, test_weighted_avg_F1, test_kappa, test_PPV, test_TPR, test_F1 = SGDR2(row['Model'],row['maxlen'],row['batch_size'],row['lr'],row['n_cycles'],row['cycle_len'],row['cycle_mult'],index)                     \n",
    "    ts_end = time.time()\n",
    "    Experiment.at[index,'duration']=(ts_end - ts_start)/60  \n",
    "\n",
    "    Experiment.at[index,'weighted_avg_F1']=val_weighted_avg_F1\n",
    "    Experiment.at[index,'kappa']=val_kappa\n",
    "    Experiment.at[index,'lizon-precision']=val_PPV\n",
    "    Experiment.at[index,'lizon-recall']=val_TPR\n",
    "    Experiment.at[index,'lizon-f1-score']=val_F1\n",
    "\n",
    "    Experiment.at[index,'test_weighted_avg_F1']=test_weighted_avg_F1\n",
    "    Experiment.at[index,'test_kappa']=test_kappa\n",
    "    Experiment.at[index,'test_lizon-precision']=test_PPV\n",
    "    Experiment.at[index,'test_lizon-recall']=test_TPR\n",
    "    Experiment.at[index,'test_lizon-f1-score']=test_F1    \n",
    "  except:\n",
    "    raise\n",
    "    Experiment.at[index,'duration']=10000\n",
    "    Experiment.at[index,'comment']='Failed'\n",
    "\n",
    "\n",
    "  #---------------------------Save results to the log------\n",
    "  try:\n",
    "    SaveToExperimentLog(Experiments_file, Experiment_name, Experiment)\n",
    "  except:\n",
    "    #Continue training even if there is an issue\n",
    "    print('Error saving to file!')  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPowqFVy8nkYrDWtV7S9D7D",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "lizon_finetuning_experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
